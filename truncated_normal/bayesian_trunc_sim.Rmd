---
title: "Bayesian Linear Regression Simulations With Truncated & Censored Normal Distributions"
author: Phil Chapman
date: 2018-07-06
output: 
    html_document:
        number_sections: yes
        theme: cosmo
        highlight: tango
        toc: yes
        toc_depth: 3
        code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

# Setup
## Load libraries

```{r, message=FALSE}
library(ggplot2, quietly = TRUE)
library(dplyr, quietly = TRUE)
library(tidybayes, quietly = TRUE)
library(brms, quietly = TRUE)
library(broom, quietly = TRUE)
library(future, quietly = TRUE)
library(purrr, quietly = TRUE)
library(furrr, quietly = TRUE)

```

## Simulate a dataset

In this section we simulate a dataset containing two groups of normally distributed data with the same variance but with a mean differing by 50.

### Define a function to make the data

Since we are going to do this repeatedly later on in the simulation section, it makes sense to define a function:

```{r}
make_data <- function(d=50, ub=600, g1=500, sd=80, n=1000) {
    data_frame(p1 = rbinom(n, 1, 0.5),
               d = d,
               data = rnorm(n, mean = g1 + p1 * d , sd=sd),
               censored = ifelse(data >= ub, 1, 0),
               cens_data = ifelse(censored == 1, ub, data),
               trunc_data = ifelse(censored == 1, NA, data))
}
```

The parameters of the function above are as follows:

- `d` is the difference between the mean of the two groups
- `ub` is the upper bound of what can be measured, ie the censoring/truncation value
- `g1` is the mean of the group with the lowest mean
- `sd` is the standard deviation of both groups
- `n` is the number of data points to be simulated.

### Make the data

Now use the function above to make some data:

```{r}
set.seed(1234)
test_data <- make_data(d=50, ub=600, g1=500, sd=80, n=1000)
test_data
```

### Plot the data

To visualise the original, truncated and censored data, we first need to change the data format slightly:

```{r}
p1_data <- test_data %>%
    select(p1, data, cens_data, trunc_data) %>%
    tidyr::gather('dataset', 'value', -p1) %>%
    filter(!is.na(value) )
```

Now plot:
```{r}
p1 <- ggplot(p1_data, aes(x=value, fill=as.factor(p1))) + 
  geom_histogram(bins=50) +
  facet_grid(as.factor(p1)~dataset, scales = 'free_y') + 
  theme_bw()
p1
```

### Calculate means and standard deviations

Use the `mean` and `sd` functions to calculate mean and standard deviation for each dataset by group:

```{r}
p1_data %>%
    group_by(dataset, p1) %>%
    summarise(mean(value), sd(value))
```

The original data gives a mean of ~500 and sd's for the two groups around ~80, whilst the truncated and censored data give means that don't agree with the original data. 

# Introduce the models

We now use linear regression to estimate the means of the original data.  Simply using lm on the original data is equivalent to calculating a mean as per the previous section.  However, in a Bayesian framework we can do linear regression with censored or truncated data too. Here we define those models and get an initial idea of how effectively they work.

## Simple linear regression with lm

Simple linear regression can be carried out using the `lm` function as follows:

```{r}
lm_mod <- lm(data ~ p1, data=test_data)
```
Look at a summary of this model:

```{r}
summary(lm_mod)
```

Now just extract the coefficients:

```{r}
broom::tidy(lm_mod)
```

So the intercept represents the mean of the lower group (where p1 is 0) and the p1 coefficient represents the difference between groups (or `d` as originally defined).

## Simple Bayesian linear regression with brms

We can use the `brms` package to estimate parameters too in a relatively simple way.  The differences are that we have to provide some priors, and also control how the MCMC sampler behaves:

```{r brms-lm-test}
brms_mod <- brm(formula = data  ~ p1, data=test_data, 
               prior = c(set_prior("normal(500, 1000)", class='Intercept'),
                         set_prior("normal(0,200)", class = "b"),
                         set_prior("cauchy(0, 40)", class = "sigma")),
               chains = 4, iter = 2000, cores=4, silent = TRUE, refresh = 0 ) 
```

This model took about 60 seconds to fit.  However, most of that was compiling the model and we can avoid that in future by updating the model with new data which will speed things up a bit.

Examining the model specification, the formula is identical to that used with the `lm` package, but what are these priors?  Effectively this contains information on what we know about the parameters we are trying to estimate before we start.  Very little information is being provided with these priors, it is effectively just starting the process off.  

To get a sense of how little information is contained in the priors, let's plot them against the data.  The dashed lines are the priors for the intercept (green) and difference (purple), the solid lines are the data,:

```{r}
ggplot(test_data) + 
    geom_density(aes(x=data, color=as.factor(p1))) +
    geom_density(data=data.frame(x=rnorm(10000, 500, 1000)), mapping=aes(x=x), color='darkgreen', linetype='dashed') +
    geom_density(data=data.frame(x=rnorm(10000, 0, 200)), mapping=aes(x=x), color='purple', linetype='dashed') +
    theme_bw()
    
```

Now let's look at the model output:

```{r}
brms_mod
```

And finally grab the coefficient estimates:

```{r}
broom::tidy(brms_mod)
```

The numbers are almost exactly the same as those from `lm`:

```{r}
broom::tidy(lm_mod)
```

## Bayesian linear regression on truncated data with brms

The benefit of using a Bayesian approach is that distributions which don't have an analytical solution can be included in the model.  In this case we define a model where the data is truncated with an upper bound of 600:

```{r brms-trunc}
brms_mod_trunc <- brm(formula = trunc_data | trunc(ub=600)  ~ p1, data=test_data, 
               prior = c(set_prior("normal(500, 1000)", class='Intercept'),
                         set_prior("normal(0,200)", class = "b"),
                         set_prior("cauchy(0, 40)", class = "sigma")),
               chains = 4, iter = 2000, cores=4, init_r=5, silent = TRUE, refresh = 0 ) 
```

The differences are:

- we use the truncated data from the test_data data frame as the response variable
- we specify the response distribution is truncated using the `| trunc(ub=600)` notation
- we add the `init_r=5` parameter which helps the sampler get started

Now let's look at the model output:

```{r}
brms_mod_trunc
```

And finally grab the coefficient estimates:

```{r}
broom::tidy(brms_mod_trunc)
```

Compare these to the simple Bayesian linear model (which was almost identical to the output of `lm`):

```{r}
broom::tidy(brms_mod)
```

## Bayesian linear regression with censored data with brms

The difference between truncated and censored data is that with censored data the data points are still present in the dataset rather than having been filtered out.  We can model this too:

```{r brms-cens}
brms_mod_cens <- brm(formula = cens_data | cens(censored)  ~ p1, data=test_data, 
               prior = c(set_prior("normal(500, 1000)", class='Intercept'),
                         set_prior("normal(0,200)", class = "b"),
                         set_prior("cauchy(0, 40)", class = "sigma")),
               chains = 4, iter = 2000, cores=4, init_r=5, silent = TRUE, refresh = 0 ) 
```

The differences are:

- we use the censored data from the test_data data frame as the response variable
- we specify that the response distribution is censored and the marker variable using the `| cens(censored)` notation
- we add the `init_r=5` parameter which helps the sampler get started


Now let's look at the model output:

```{r}
brms_mod_cens
```

And finally grab the coefficient estimates:

```{r}
broom::tidy(brms_mod_cens)
```

Compare these to the simple Bayesian linear model (which was almost identical to the output of `lm`):

```{r}
broom::tidy(brms_mod)
```

## Compare all models

To compare the output of the Bayesian models, we can plot the posterior distributions.  First, extract the posterior samples from each model:

```{r}
plot_samples <- list()
plot_samples[[1]] <- brms_mod %>%
    gather_samples(b_Intercept, b_p1, sigma) %>%
    mutate(model='normal')

plot_samples[[2]] <- brms_mod_trunc %>%
    gather_samples(b_Intercept, b_p1, sigma) %>%
    mutate(model='truncated')

plot_samples[[3]] <- brms_mod_cens %>%
    gather_samples(b_Intercept, b_p1, sigma) %>%
    mutate(model='censored')
```

Now bind rows together and plot:

```{r}
bind_rows(plot_samples) %>%
    ggplot(aes(x=model, y=estimate)) + 
    geom_eye() + coord_flip() + facet_wrap(~term, scales = 'free') + theme_bw()
```

Censored and normal are almost identical, truncated is slightly inaccurate. 

# Simulation experiment

In this section, we seek to simulate data from a range of parameters and then see how each model performs in different situations.  To do this we need combinations of parameters, and then a number of datasets per parameter combination.  We then compare the accuracy of each model against the baseline, which will be the normal linear regression with `lm`.

To carry out simulations, it is useful to use the tidyverse suite of tools especially the `purrr` package and its `map` function.  See this blog post for more information on this approach: https://chapmandu2.github.io/post/2017/02/21/bioinformatics-in-the-tidyverse/ 

## Simulate the data

### Define parameter grid

First of all we use the `tidyr::crossing` function to simulate a data frame which is a grid of values which can then be fed into the `make_data` function that we prepared:

```{r}
#params_df <- tidyr::crossing(d=c(25, 50, 100), ub=600, g1=c(400, 450, 500, 550), sd=80, n=1000) %>%
params_df <- tidyr::crossing(d=50, ub=600, g1=c(400, 500), sd=80, n=1000) %>%
        mutate(param_id = row_number()) %>%
    tidyr::crossing(sim_id=1:10)
params_df
```

For each of the `r nrow(params_df)` rows in the data frame we need to create a dataset for each.

### Simulate data for each set of parameters

To simulate the data we _apply_ the `make_data` function to each row in the `params_df` data frame using the `pmap` function from `purrr`:

```{r}
sim_data <- params_df %>%
    mutate(data = pmap(.l=list(d=d, ub=ub, g1=g1, sd=sd, n=n), .f=make_data))
```

The `pmap` function takes multiple inputs, since our `make_data` function has multiple input parameters.  For simpler functions with just a single parameter, or where only one parameter is provided by data in the data frame we can just use map.

We now have a data frame where the data column is actually a list-col containing data frames:

```{r}
sim_data
```

We can access one of these data frames using list notation:

```{r}
sim_data$data[[1]]
```


## Fit the models

Now we can fit the models to the simulated data in each row of the data frame, again using functions in `purrr`.

### Fit the simple linear model to simulated data

To start with, let's just fit the linear model.  This is achieved as follows:

```{r}
test_lm_df <- sim_data %>%
    mutate(lm_mod=map(data, ~lm(data ~ p1, data=.)))
test_lm_df
```

Now we have an lm object for each set of simulated data.  We can again access this as if it were a list:

```{r}
broom::tidy(test_lm_df$lm_mod[[1]])
```

There's quite a lot going on in a relatively compact expression, but what we're doing is mapping the data column (ie the data frame per row) into a call to the `lm` function.  The tilde (`~`) is shorthand and let's us refer to the object we're passing in as a period (`.`)  An alternative would be:

```{r eval=FALSE}
test_lm_df <- sim_data %>%
    mutate(lm_mod=map(.x=data, .f=function(x) {
        lm(data ~ p1, data=x)
        }))
```

But ultimately what we've done is repeat the linear model fit across all of our different simulated datasets.

### Fit the normal brms model to simulated data

Fitting the brms model follows the same pattern, with two key differences:

- Instead of making a new brms model each time, we can update the one we already created. This is much quicker since it avoids that slow compiling step.
- Instead of using map we use `future_map` from the amazing `furrr` package.  This package combines easy parallelisation from the `future` package with the nice `map` functions we used before.

First we plan for parallelisation:

```{r}
plan(multicore)
```

Now fit the simple bayesian linear model to each simulated dataset.  Using `future_map` allows R to use all available cores for the work rather than 1.  We use `update` rather than `brm` and map the simulated data from each row into the `newdata` parameter.  Setting `recompile` to FALSE ensures that the lengthy recompiling step is avoided, and we only use 1 core per model fit since future is already taking care of parallisation for us.

```{r test-brm-multi}
test_brm_df <- sim_data %>%
    mutate(b_mod = future_map(data, ~update(brms_mod, newdata=., recompile=FALSE, 
                                            chains=4, iter=1000, init_r=5, cores=1)))
```

And we now we have a brmsfit object for each dataset!   

```{r}
test_brm_df
```

One thing to note is that storing all of these objects makes for a big data frame so we have to be careful:

```{r}
pryr::object_size(test_brm_df)
```

### Fit all models at once to simulated data

Having laid the groundwork we can now fit all of the models in a single dataframe as follows:

```{r sim-all-models}
sim_models <- sim_data %>%
    mutate(lm_mod=map(data, ~lm(data ~ p1, data=.)),
           brms_mod=future_map(data, ~update(brms_mod, newdata=., recompile=FALSE, 
                                            chains=4, iter=1000, init_r=5, cores=1)),
           brms_mod_trunc=future_map(data, ~update(brms_mod_trunc, newdata=., recompile=FALSE, 
                                            chains=4, iter=1000, init_r=5, cores=1)),
           brms_mod_cens=future_map(data, ~update(brms_mod_cens, newdata=., recompile=FALSE, 
                                            chains=4, iter=1000, init_r=5, cores=1)))
```

We do need to beware a little when doing this since we aren't properly checking the brms models for basic things like convergence etc.  But since we know the 'truth' anyway this isn't so bad, models gone wrong will show up anyhow.

This dataframe is going to be even bigger:

```{r}
pryr::object_size(sim_models)
```


## Extract the parameters

Below code is a bit complex but we are extracting the parameter estimates from the lm and brms models and then putting them on the same line.  So there is one line per brms model and each has the lm model coefficients plus those from the brms model.  Then work out differences between them.

TO DO: break this down to make it more understandable

```{r}
result_df <- sim_models %>%
    select(param_id, sim_id, lm_mod, brms_mod, brms_mod_trunc, brms_mod_cens) %>%
    filter(map_dbl(brms_mod, brms::nsamples) > 0, 
           map_dbl(brms_mod_cens, brms::nsamples) > 0,
           map_dbl(brms_mod_trunc, brms::nsamples) > 0) %>%
    mutate(lm_intercept = map_dbl(lm_mod, ~coef(.)[[1]]),
           lm_p1 = map_dbl(lm_mod, ~coef(.)[[2]])) %>%
    tidyr:: gather('model', 'object', starts_with('brms')) %>%
    mutate(brms_coef = map(object, ~broom::tidy(.) %>% select(1:2) %>% tidyr::spread(term, estimate))) %>%
    select(-lm_mod, -object) %>%
    tidyr::unnest() %>%
    mutate(diff_intercept = lm_intercept - b_Intercept,
           diff_p1 = lm_p1 - b_p1) %>%
    inner_join(params_df, by=c('param_id', 'sim_id'))


```

## Plot the results

Now plot the results.  We are interested in the difference between the actual and estimated parameter:

### Intercept

```{r}
result_df %>%
    dplyr::filter(g1 < 600) %>%
    ggplot(aes(color=as.factor(g1), y=b_Intercept, x=g1)) + 
    geom_boxplot() + 
    facet_grid(as.factor(d)~model) +
    theme_bw()

```

### Difference between groups

```{r}
result_df %>%
    dplyr::filter(g1 < 600) %>%
    ggplot(aes(color=as.factor(g1), y=b_p1, x=g1)) + 
    geom_boxplot() + 
    facet_grid(as.factor(d)~model) +
    theme_bw()

```

# TO DO

- Healthcheck of MCMCs - maybe effective samples and Rhat for each model?
- Shiny app to explore output
- Try shiny stan on all models?
- Try to parallelise further - eg on 128 core EC2 instance?

# Conclusion

# Export data

```{r}
save(result_df, sim_data, params_df, file = '~/StatisticalRethinking/truncated_normal/bayesian_trunc_sim_output/sim_output.RData')
```


# Session Info
```{r}
Sys.time()
sessionInfo()
cat(paste(readLines('/etc/docker/docker_info.txt'), '\n'))
```